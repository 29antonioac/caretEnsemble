---
title: "A brief introduction to caretEnsemble"
author: "Zach Mayer"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\usepackage[utf8]{inputenc}
---

caretEnsemble is a package for making ensembles of caret models.  You should already be somewhat familiar with the caret package before trying out caretEnsemble.

caretEnsemble has 2 primary methods for creating ensembles: caretEnsemble, which uses greedy optimization to create a simple linear blend of models and caretStack which uses a caret model to combine the outputs from several component caret models.

## caretEnsemble

To start, we need 2 or more caret models, fit on the same training dataset, using the same resampling strategy.  It is *extremely important* to use the *exact same* indexes in each models `trControl` argument.  The best way to do this is to create a single `trainControl` object (with explicit indexes) and pass it to both models:

```{r, echo=TRUE}
#Adapted from the caret vignette
suppressMessages(library('caret'))
suppressMessages(library('mlbench'))
data(Sonar)
set.seed(107)
inTrain <- createDataPartition(y = Sonar$Class, p = .75, list = FALSE)
training <- Sonar[ inTrain,]
testing <- Sonar[-inTrain,]
my_control <- trainControl(
  method='boot',
  number=25,
  savePredictions=TRUE,
  classProbs=TRUE,
  index=createResample(training$Class, 25),
  summaryFunction=twoClassSummary
  )
```

Once we have a common train control, we can fit 2 different predictive models using the `train` function from caret:
```{r, echo=TRUE, fig.show='hold'}
suppressMessages(library('pROC'))
suppressMessages(library('rpart'))
suppressWarnings(model_glm <- train(Class ~ ., training, method='glm', preProc = c("center", "scale"), trControl=my_control, metric='ROC'))
suppressWarnings(model_rpart <- train(Class ~ ., training, method='rpart', trControl=my_control, metric='ROC'))
model_list <- list(logit=model_glm, tree=model_rpart)
xyplot(resamples(model_list))
```

As you can see from this plot, these 2 models are pretty un-correllated, but the rpart model is ocassionally anti-predictive.

We can confirm the 2 model's correllations with the `modelCor` function from caret:
```{r, echo=TRUE}
modelCor(resamples(model_list))
```

These models make a good candidate for an ensemble: their predicitons are fairly un-correllated, but their overall accuaracy is similar.  We do a simple, linear greedy optimization on AUC using caretEnsemble:
```{r, echo=TRUE}
suppressMessages(library('caretEnsemble'))
greedy_ensemble <- caretEnsemble(model_list)
summary(greedy_ensemble)
```

The ensemble's AUC on the training set resamples is 0.76, which is about 6% better than the best individual model.  We can confirm this finding on the test set:
```{r, echo=TRUE}
suppressMessages(library('caTools'))
model_preds <- lapply(model_list, predict, newdata=testing, type='prob')
model_preds <- lapply(model_preds, function(x) x[,'M'])
model_preds <- data.frame(model_preds)
suppressWarnings(model_preds$ensemble <- predict(greedy_ensemble, newdata=testing))
colAUC(model_preds, testing$Class)
```
The ensemble's AUC on the test set is about 7% higher than the best individual model.

## caretStack


## Figures

## More Examples
